{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11. Callback  Function.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPDc+GfdH1qWE7UtUdpt2V9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jong9810/TensorFlow-2.0/blob/main/11_Callback_Function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. TensorFlow Callback Function"
      ],
      "metadata": {
        "id": "mnk1BwfqVuB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callback 개념"
      ],
      "metadata": {
        "id": "_2Y5N_lcV5r-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 알람시계와 비슷한 원리\n",
        "1. 먼저 특정한 상황에서 실행되는 함수를 시스템에 등록해 둔다.\n",
        "2. 해당 상황이 발생했을 때 등록되어 있는 함수가 실행 되고\n",
        "3. 시스템에서의 결과를 통해서 개발자는 등록된 콜백 함수가 실행된 것을 알 수 있다."
      ],
      "metadata": {
        "id": "QCYSRtPuV5ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow Callback Function"
      ],
      "metadata": {
        "id": "8sYyuCrCV5yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- TensorFlow에는 다양한 콜백 함수가 있는데, 모델의 학습 방향, 저장 시점 그리고 학습 정지 시점 등에 관한 상황을 모니터링하기 위해 주로 사용됨\n",
        "- 학습 도중에 학습율을 변화시키거나, 일정 시간이 지나도 검증 데이터 손실 값이 개선되지 않으면 학습을 멈추게 하는 등의 작업을 수행함\n",
        "1. ReduceLPOnPlateau : 학습 중에 학습율을 변화시키는 함수\n",
        "2. ModelCheckpoint : 모델의 가중치값을 중간에 저장하도록 하는 함수\n",
        "3. EarlyStopping : 모델 성능 지표가 일정 시간동안 개선되지 않을 때 조기 종료하도록 하는 함수"
      ],
      "metadata": {
        "id": "-kLZRINSV51m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. ReduceLROnPlateau\n",
        "- 모델의 성능 개선이 없을 경우, 학습율을 조절해서 모델의 개선을 유도하는 콜백 함수\n",
        "1. 파라미터\n",
        "- monitor : 무엇을 기준으로 함수를 실행할 지 지정\n",
        "- factor : 통해 학습율을 얼만큼 줄일지 지정\n",
        "- patience : 얼마만큼 epoch 동안 개선이 안될 시 함수 실행할 지 지정\n",
        "- verbose : 로그를 출력할 형식을 지정\n",
        "2. 예시\n",
        "- reduceLR = ReduceLROnPlateau(monitor='val_loss', factpr=0.5, patience=5, verbose=1)\n",
        "- hist = model.fit(x_train, t_train, epochs=50, validation_split=0.2, callbacks=[reduceLR])\n",
        "- callbacks=[] : 콜백 함수를 시스템에 지정"
      ],
      "metadata": {
        "id": "GqBrRdh7V54t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. ModelCheckpoint\n",
        "- 모델의 학습 중에 조건을 만족했을 때 현재의 가중치를 중간 저장해줌\n",
        "- 이점 : 모델의 학습 시간이 엄청나게 오래 걸리는 경우, 중간에 memory overflow나 crush가 나더라도 다시 가중치를 불러와서 학습을 이어나갈 수 있음. => 학습시간 단축\n",
        "1. 파라미터\n",
        "- file_path : 저장할 파일의 경로\n",
        "- monitor : 어떤 값이 개선되었을 때 호출할 지 지정\n",
        "- verbose : 로그 출력 형식을 지정\n",
        "- save_best_only : best 값만을 저장할 것인지 결정\n",
        "- mode : 만약 'auto'라면 자동으로 best 값을 찾음\n",
        "2. 예시\n",
        "- file_path = './modelchpoint_test.h5'\n",
        "- checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "- hist = model.fit(x_train, t_train, epochs=50, validation_split=0.2, callbacks=[checkpoint])\n",
        "\n"
      ],
      "metadata": {
        "id": "POO_vduZV57m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. EarlyStopping\n",
        "- 모델 성능 지표가 우리가 설정한 epoch 동안 개선되지 않으면 조기 종료함\n",
        "- 일반적으로 EarlyStoppin과 ModelCheckpoint를 조합해서 개선되지 않는 학습에 대해 조기 종료를 하고 ModelCheckpoint로 best model을 다시 로드하여 학습을 재게한다.\n",
        "1. 파라미터\n",
        "- monitor : 어떤 값이 개선되지 않을 때 함수를 호출할 지 지정\n",
        "- patience : 몇 번의 epoch 동안 개선되지 않으면 함수를 호출할 지 지정\n",
        "2. 예시\n",
        "- file_path = './modelchpoint_test.h5'\n",
        "- checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "- stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "- hist = model.fit(x_train, t_train, validation_split=0.2, callbacks=[checkpoint, stopping])"
      ],
      "metadata": {
        "id": "V8e7bGcIV5-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callback Function 예제 - MNIST"
      ],
      "metadata": {
        "id": "JlTvQK2dV6BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "W5oYOIZsV6Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터 불러오기\n",
        "(x_train, t_train), (x_test, t_test) = mnist.load_data()\n",
        "\n",
        "# print(x_train.shape, t_train.shape)\n",
        "# print(x_test.shape, t_test.shape)"
      ],
      "metadata": {
        "id": "J1kmZHJEV6H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(t_train)\n",
        "# print(t_test)"
      ],
      "metadata": {
        "id": "ff5pDPrIeW4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.imshow(x_train[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2ThgVkVYV6K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 데이터 전처리 과정\n",
        "# 이미지 데이터 정규화\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# 정답 데이터 원핫 인코딩\n",
        "t_train = tf.keras.utils.to_categorical(t_train, num_classes=10)\n",
        "t_test = tf.keras.utils.to_categorical(t_test, num_classes=10)"
      ],
      "metadata": {
        "id": "Wr4RiqrKV6OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(t_train)\n",
        "# print(t_test)"
      ],
      "metadata": {
        "id": "WtW36nG_V6RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "_ITRVLKjV6Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=(28,28))) # 28 * 28 크기의 2차원 이미지를 784개의 1차원 벡터로 변환\n",
        "model.add(Dense(100, activation='relu')) # 은닉층 (활성화 함수 : 'relu', 노드 수 : 100개)\n",
        "model.add(Dense(10, activation='softmax')) # 출력층 (활성화 함수 : 'softmax', 노드 수(=정답 수) : 10개)\n",
        "\n",
        "# 원핫 인코딩 방식이므로 loss는 'categorical_crossentropy'\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "9v_aG_bae-GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "file_path = './modelchpoint_test.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', save_best_only=True, mode='auto', verbose=1)\n",
        "stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "hist = model.fit(x_train, t_train, epochs=30, validation_split=0.2, callbacks=[checkpoint, stopping])"
      ],
      "metadata": {
        "id": "xkWYQDQoe-I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "\n",
        "hist = model.fit(x_train, t_train, epochs=30, validation_split=0.2, callbacks=[reduceLR])"
      ],
      "metadata": {
        "id": "r52nzgWje-L-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}