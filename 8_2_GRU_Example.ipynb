{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8-2. GRU Example.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/6Zyq1qADGzzLRAkvDOdW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jong9810/TensorFlow-2.0/blob/main/8_2_GRU_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8-2. GRU Example : 삼성전자 주가 예측"
      ],
      "metadata": {
        "id": "wwxc1qZ3v5eV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 머신러닝 프로그램 개발 프로세스\n",
        "1. 데이터 로드 및 분포 확인 (그래프 그려보기)\n",
        "1. 데이터 전처리 (Outlier, Missing value, 정규화, 표준화, One-Hot Encoding, feature / label 데이터 정의 등)\n",
        "1. 데이터 생성 (feature / label 데이터를 시계열 데이터 형식으로 변환, window size, horizontal factor 지정)\n",
        "1. 데이터 분리 및 모델 구축\n",
        "1. 데이터 예측 및 모델 평가 (정확도, 손실함수 값, 오차 등 그래프로 그려보기)"
      ],
      "metadata": {
        "id": "Thg66HuRwA8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "Y2wz_0bRwA_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브를 구글 코랩에 마운트 시킴\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "T6aJfrX8wBC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터 로드 및 분포 확인\n",
        "raw_df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/dataset/005930.KS_3MA_5MA.csv')\n",
        "raw_df.head()"
      ],
      "metadata": {
        "id": "iad2I5tuwBGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(raw_df['Adj Close'], label='Adj Close', color='blue')\n",
        "\n",
        "plt.title('SAMSUNG ELECTRONIC STOCK PRICE')\n",
        "plt.xlabel('period (day)')\n",
        "plt.ylabel('price (won)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KWvJccswwBJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 데이터 전처리\n",
        "raw_df.describe()"
      ],
      "metadata": {
        "id": "aoFTOpMNwBL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 열에 NaN 값이 몇 개 있는지 출력\n",
        "raw_df.isnull().sum()"
      ],
      "metadata": {
        "id": "T2wlYXoTwBPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df.loc[raw_df['Open'].isna()]  # raw_df의 데이터 중 'Open' 열의 값이 NaN인 행을 모두 출력함\n",
        "\n",
        "# raw_df의 데이터 중 'Volume' 열의 값이 0인 셀을 찾아서 NaN 값으로 바꿈\n",
        "# => describe() 함수에서 Volume 열의 최소값이 0이었기 때문에 replace()함수로 대체해줌\n",
        "raw_df['Volume'] = raw_df['Volume'].replace(0, np.nan)\n",
        "\n",
        "raw_df.isnull().sum()"
      ],
      "metadata": {
        "id": "dLmmCczjwBRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터의 0 값 모두 NaN으로 잘 바뀌었는지 확인\n",
        "for col in raw_df.columns:\n",
        "    missing_rows = raw_df.loc[raw_df[col]==0].shape[0]\n",
        "    print(col + ' : ' + str(missing_rows))"
      ],
      "metadata": {
        "id": "P-h3t9AEwBUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df = raw_df.dropna() # NaN 값이 있는 행의 데이터를 모두 삭제해줌\n",
        "raw_df.isnull().sum()"
      ],
      "metadata": {
        "id": "odCC37gzwBXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 생성\n",
        "from sklearn.preprocessing import MinMaxScaler # 데이터를 정규화 해주는 함수"
      ],
      "metadata": {
        "id": "ZaaRrqiLwBaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "\n",
        "scale_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', '3MA', '5MA']\n",
        "scaled_df = scaler.fit_transform(raw_df[scale_cols])\n",
        "# print(type(scaled_df))\n",
        "# print(scaled_df)"
      ],
      "metadata": {
        "id": "b2Ha7mbU4jMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df = pd.DataFrame(scaled_df, columns=scale_cols)\n",
        "# print(scaled_df, type(scaled_df))"
      ],
      "metadata": {
        "id": "zDTD7Tse4wkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = ['3MA', '5MA', 'Adj Close']\n",
        "label_cols = ['Adj Close']\n",
        "\n",
        "feature_df = pd.DataFrame(scaled_df, columns=feature_cols)\n",
        "label_df = pd.DataFrame(scaled_df, columns=label_cols)\n",
        "\n",
        "# print(feature_df)\n",
        "# print(label_df)\n",
        "\n",
        "feature_np = feature_df.to_numpy()\n",
        "label_np = label_df.to_numpy()\n",
        "\n",
        "# print(type(feature_np))\n",
        "# print(type(label_np))"
      ],
      "metadata": {
        "id": "-VSsevZ74wn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_sequence_dataset(feature, label, w, h):\n",
        "    feature_list = []\n",
        "    label_list = []\n",
        "\n",
        "    for i in range(len(feature) - w - h + 1):\n",
        "        feature_list.append(feature[i:i+w])\n",
        "        label_list.append(label[i+w+h-1])\n",
        "\n",
        "    return np.array(feature_list), np.array(label_list)"
      ],
      "metadata": {
        "id": "q-4JXJHx4wqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = 40 # window size\n",
        "h = 1 # horizontal factor\n",
        "\n",
        "X, Y = make_sequence_dataset(feature_np, label_np, w, h)"
      ],
      "metadata": {
        "id": "utzQRW9S4wte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4, 데이터 분리 및 모델 구축\n",
        "split = -200\n",
        "x_train = X[:split]\n",
        "y_train = Y[:split]\n",
        "\n",
        "x_test = X[split:]\n",
        "y_test = Y[split:]\n",
        "\n",
        "# print(x_train.shape, y_train.shape)\n",
        "# print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "NYH2x5TC4ww1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU"
      ],
      "metadata": {
        "id": "qSsnL-0x9ZuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(GRU(256, activation='tanh', input_shape=x_train[0].shape))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "45KJnx8D4wz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "4HzUHWJyA3C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse', metrics=['mae'], optimizer='adam')\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=16, callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "HZXxJirm4w2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.title('3MA + 5MA + Adj Close, window_size=40')\n",
        "plt.xlabel('period')\n",
        "plt.ylabel('adj close')\n",
        "plt.plot(y_test, label='actual')\n",
        "plt.plot(pred, label='prediction')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.show"
      ],
      "metadata": {
        "id": "CDn5_vTF4w5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "Wwye9_CS4jPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM Vs. GRU\n",
        "- LSTM과 GRU 모두 시계열 데이터(ex. 주식 데이터)를 분석, 예측하기에 적합한 구조라는 것을 알 수 있었음\n",
        "- 다만 LSTM은 업데이트하는 가중치, 바이어스가 GRU보다 많아서 계산량은 더 많고 정확도는 좀 더 높다는 것도 알 수 있었다.\n",
        "- 따라서 분석하고자 하는 문제와 데이터, 도메인 등에 따라 GRU를 사용할지 LSTM을 사용할지를 적절히 선택하는 것이 중요하다."
      ],
      "metadata": {
        "id": "_sg1N-rpCPm7"
      }
    }
  ]
}