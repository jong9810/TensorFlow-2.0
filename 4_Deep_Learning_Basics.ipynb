{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. Deep Learning Basics.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdb2PURldX5BJoX2DtuaZn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jong9810/TensorFlow-2.0/blob/main/4_Deep_Learning_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Deep Learning"
      ],
      "metadata": {
        "id": "lEqMWLk035XI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning Basics"
      ],
      "metadata": {
        "id": "R8C-s2IxARbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "t_ckWdeK4cgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = np.array([2,4,6,8,10,12,14,16,18,20]).astype('float32')\n",
        "t_data = np.array([0,0,0,0,0,0,1,1,1,1]).astype('float32')\n",
        "print('x_data.shape =', x_data.shape, 't_data.shape =', t_data.shape)"
      ],
      "metadata": {
        "id": "QI77na1L4clF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8, input_shape=(1, ), activation='sigmoid')) # 입력층 (input_shape=('입력 노드 수', )), 은닉층 (노드 수 : 8) 설정\n",
        "model.add(Dense(1, activation='sigmoid')) # 출력층 (노드 수 : 1) 설정"
      ],
      "metadata": {
        "id": "FvUDHlW54cpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(SGD(learning_rate=0.1), loss='binary_crossentropy', metrics=['accuracy']) # binary_crossentropy : 이항분류 문제일 때 손실함수\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "5_p26miJ4cs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_data, t_data, epochs=500)"
      ],
      "metadata": {
        "id": "xGuOAit_4cwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = np.array([0.5, 3.0, 3.5, 11.0, 13.0, 31.0])\n",
        "\n",
        "sigmoid_value = model.predict(test_data) # activation이 sigmoid이기 때문에 predict 함수의 return 값은 0과 1 사이의 값 (어떤 사건이 발생할 확률)\n",
        "\n",
        "logical_value = tf.cast(sigmoid_value > 0.5, dtype=tf.float32) # sigmoid_value 가 0.5 보다 크면 1, 작거나 같으면 0 저장\n",
        "# tf.cast(조건, 데이터 타입)  :  조건이 참이면 1, 거짓이면 0 저장\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "    print(test_data[i], sigmoid_value[i], logical_value.numpy()[i])"
      ],
      "metadata": {
        "id": "ZduJuAYz4czu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 딥러닝 개발 프로세스\n",
        "1. 데이터 정의 : 모델에 학습시킬 데이터를 불러오는 과정\n",
        "1. 데이터 전처리 : 학습 데이터가 이미지인 경우, 데이터에 대한 정규화(원핫 인코딩)가 필요함 ->> (tensorflow 에서는 to_categorical() API를 통해 수행)\n",
        "1. 모델 구축 : 모델을 생성하고 model.add()를 통해 입력, 은닉, 출력층을 구축하는 과정\n",
        "1. 모델 컴파일 : model.compile() API를 이용하여 optimizer, loss function 등을 지정하는 과정. ->> (원핫 인코딩 : loss='categorical_crossentropy' else : 'sparse_categorical_crossentropy')\n",
        "1. 학습 : model.fit() API 이용하여 데이터를 학습하는 과정\n",
        "1. 모델 평가 : model.evaluate() API를 이용하여 테스트 데이터에 대한 정확도를 측정, 혼동 행렬(confusion matrix) 등 모델의 강점, 약점 등을 파악하는 과정"
      ],
      "metadata": {
        "id": "xoBk8qgSBn2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 참고 (ANN(Artificial Neural Network), CNN(Covolutional Neural Network) 모델 구축 함수)\n",
        "1. ANN : 은닉층을 구성할 때, 주로 Dense() 함수 사용\n",
        "1. CNN : 은닉층을 구성할 때, 주로 Conv2D(), MaxPool2D(), Flatten() 등 함수 사용"
      ],
      "metadata": {
        "id": "T5MeESZy4c6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리 과정\n",
        "1. 정규화 (Normalization)\n",
        "- 딥러닝에서 입력 데이터의 상대적 크기에 대한 영향을 줄이기 위해, MinMax 공식을 이용하여 모든 데이터 범위를 0~1 사이로 변환하는 과정\n",
        "- MinMax 공식 : data(new) = (data-Min) / (Max - Min)\n",
        "\n",
        "2. 표준화 (Standardization)\n",
        "- 딥러닝 모델이 더 높은 precision을 가질 수 있도록, 다음과 같은 데이터 평균(Mean)과 표준편차(Std)를 이용하여 특정 범위를 벗어난 데이터는 ourlier로 간주하여 제거하는 과정\n",
        "- data(new) = (data - Mean) / Std\n",
        "\n",
        "3. 원핫 인코딩 (One-Hot Encoding)\n",
        "- 정답 개수와 동일한 크기를 가지는 리스트를 만든 후 정답에 해당하는 리스트의 인덱스 값에는 1, 나머지 인덱스에는 모두 0을 넣어 정답을 표현하는 방식\n",
        "- 즉, 리스트에서 가장 큰 값을 가지는 인덱스를 정답으로 인식"
      ],
      "metadata": {
        "id": "tX0X64PU4c-T"
      }
    }
  ]
}